\contentsline {section}{\numberline {1}Framing}{4}{section.1}%
\contentsline {subsection}{\numberline {1.1}Labels}{4}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Features}{4}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Models}{4}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}Regression or Classification}{4}{subsection.1.4}%
\contentsline {section}{\numberline {2}Descending into ML}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Linear Regression}{5}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Training and Loss}{5}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Squared Loss}{6}{subsubsection.2.2.1}%
\contentsline {subsubsection}{\numberline {2.2.2}Mean Square Error}{6}{subsubsection.2.2.2}%
\contentsline {section}{\numberline {3}Reducing Loss}{6}{section.3}%
\contentsline {subsection}{\numberline {3.1}Iterative Approach}{6}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Gradient Decent}{7}{subsection.3.2}%
\contentsline {section}{\numberline {4}First Steps with TF}{8}{section.4}%
\contentsline {section}{\numberline {5}Generalization}{8}{section.5}%
\contentsline {subsection}{\numberline {5.1}William of Ockham}{9}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Machine Learning Fine Print}{9}{subsection.5.2}%
\contentsline {section}{\numberline {6}Training and Test Sets}{9}{section.6}%
\contentsline {section}{\numberline {7}Validation}{9}{section.7}%
\contentsline {section}{\numberline {8}Representaion}{10}{section.8}%
\contentsline {subsection}{\numberline {8.1}Feature Engineering}{10}{subsection.8.1}%
\contentsline {subsubsection}{\numberline {8.1.1}Mapping Numerical Values}{10}{subsubsection.8.1.1}%
\contentsline {subsubsection}{\numberline {8.1.2}Mapping Categorical Values}{11}{subsubsection.8.1.2}%
\contentsline {subsection}{\numberline {8.2}Ensuring a Good Representation of Features}{12}{subsection.8.2}%
\contentsline {subsubsection}{\numberline {8.2.1}Use Discrete Feature Values}{12}{subsubsection.8.2.1}%
\contentsline {subsubsection}{\numberline {8.2.2}Provide Obvious Meanings}{12}{subsubsection.8.2.2}%
\contentsline {subsubsection}{\numberline {8.2.3}Don't Mix Actual Data with "Magic Numbers"}{12}{subsubsection.8.2.3}%
\contentsline {subsubsection}{\numberline {8.2.4}Account for Potential Changes with the Meanings of Feature Values}{12}{subsubsection.8.2.4}%
\contentsline {subsection}{\numberline {8.3}Cleaning Data}{13}{subsection.8.3}%
\contentsline {subsubsection}{\numberline {8.3.1}Scaling Feature Values}{13}{subsubsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.2}Handling Extreme Outliers}{13}{subsubsection.8.3.2}%
\contentsline {subsubsection}{\numberline {8.3.3}Binning}{13}{subsubsection.8.3.3}%
\contentsline {subsubsection}{\numberline {8.3.4}Scrubbing}{13}{subsubsection.8.3.4}%
\contentsline {section}{\numberline {9}Feature Crosses}{14}{section.9}%
\contentsline {section}{\numberline {10}Regularisation for Simplicity}{14}{section.10}%
\contentsline {section}{\numberline {11}Logistic Regression}{16}{section.11}%
\contentsline {subsection}{\numberline {11.1}Loss function for Logistic Regression}{16}{subsection.11.1}%
\contentsline {section}{\numberline {12}Classification}{17}{section.12}%
\contentsline {subsection}{\numberline {12.1}Thresholding}{17}{subsection.12.1}%
\contentsline {subsection}{\numberline {12.2}True vs. False, Positve vs. Negative}{17}{subsection.12.2}%
\contentsline {subsection}{\numberline {12.3}Accuracy, Precision and Recall}{17}{subsection.12.3}%
\contentsline {subsection}{\numberline {12.4}ROC and AUC}{18}{subsection.12.4}%
\contentsline {subsection}{\numberline {12.5}Prediction Bias}{18}{subsection.12.5}%
\contentsline {section}{\numberline {13}Regularization: Sparsity}{19}{section.13}%
\contentsline {section}{\numberline {14}Neural Networks}{19}{section.14}%
\contentsline {subsection}{\numberline {14.1}Hidden Layers}{20}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Activation Functions}{21}{subsection.14.2}%
\contentsline {subsection}{\numberline {14.3}Common Activation Functions}{21}{subsection.14.3}%
\contentsline {section}{\numberline {15}Best Practices when training neural networks}{22}{section.15}%
\contentsline {subsection}{\numberline {15.1}Failure Cases}{22}{subsection.15.1}%
\contentsline {subsubsection}{\numberline {15.1.1}Vanishing Gradients}{22}{subsubsection.15.1.1}%
\contentsline {subsubsection}{\numberline {15.1.2}Exploding Gradients}{22}{subsubsection.15.1.2}%
\contentsline {subsubsection}{\numberline {15.1.3}Dead ReLU Units}{22}{subsubsection.15.1.3}%
\contentsline {subsection}{\numberline {15.2}Dropout Regularization}{22}{subsection.15.2}%
