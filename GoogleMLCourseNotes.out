\BOOKMARK [1][-]{section.1}{Framing}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Labels}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Features}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Models}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Regression or Classification}{section.1}% 5
\BOOKMARK [1][-]{section.2}{Descending into ML}{}% 6
\BOOKMARK [2][-]{subsection.2.1}{Linear Regression}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.2}{Training and Loss}{section.2}% 8
\BOOKMARK [3][-]{subsubsection.2.2.1}{Squared Loss}{subsection.2.2}% 9
\BOOKMARK [3][-]{subsubsection.2.2.2}{Mean Square Error}{subsection.2.2}% 10
\BOOKMARK [1][-]{section.3}{Reducing Loss}{}% 11
\BOOKMARK [2][-]{subsection.3.1}{Iterative Approach}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.2}{Gradient Decent}{section.3}% 13
\BOOKMARK [1][-]{section.4}{First Steps with TF}{}% 14
\BOOKMARK [1][-]{section.5}{Generalization}{}% 15
\BOOKMARK [2][-]{subsection.5.1}{William of Ockham}{section.5}% 16
\BOOKMARK [2][-]{subsection.5.2}{Machine Learning Fine Print}{section.5}% 17
\BOOKMARK [1][-]{section.6}{Training and Test Sets}{}% 18
\BOOKMARK [1][-]{section.7}{Validation}{}% 19
\BOOKMARK [1][-]{section.8}{Representaion}{}% 20
\BOOKMARK [2][-]{subsection.8.1}{Feature Engineering}{section.8}% 21
\BOOKMARK [3][-]{subsubsection.8.1.1}{Mapping Numerical Values}{subsection.8.1}% 22
\BOOKMARK [3][-]{subsubsection.8.1.2}{Mapping Categorical Values}{subsection.8.1}% 23
\BOOKMARK [2][-]{subsection.8.2}{Ensuring a Good Representation of Features}{section.8}% 24
\BOOKMARK [3][-]{subsubsection.8.2.1}{Use Discrete Feature Values}{subsection.8.2}% 25
\BOOKMARK [3][-]{subsubsection.8.2.2}{Provide Obvious Meanings}{subsection.8.2}% 26
\BOOKMARK [3][-]{subsubsection.8.2.3}{Don't Mix Actual Data with "Magic Numbers"}{subsection.8.2}% 27
\BOOKMARK [3][-]{subsubsection.8.2.4}{Account for Potential Changes with the Meanings of Feature Values}{subsection.8.2}% 28
\BOOKMARK [2][-]{subsection.8.3}{Cleaning Data}{section.8}% 29
\BOOKMARK [3][-]{subsubsection.8.3.1}{Scaling Feature Values}{subsection.8.3}% 30
\BOOKMARK [3][-]{subsubsection.8.3.2}{Handling Extreme Outliers}{subsection.8.3}% 31
\BOOKMARK [3][-]{subsubsection.8.3.3}{Binning}{subsection.8.3}% 32
\BOOKMARK [3][-]{subsubsection.8.3.4}{Scrubbing}{subsection.8.3}% 33
\BOOKMARK [1][-]{section.9}{Feature Crosses}{}% 34
\BOOKMARK [1][-]{section.10}{Regularisation for Simplicity}{}% 35
\BOOKMARK [1][-]{section.11}{Logistic Regression}{}% 36
\BOOKMARK [2][-]{subsection.11.1}{Loss function for Logistic Regression}{section.11}% 37
\BOOKMARK [1][-]{section.12}{Classification}{}% 38
\BOOKMARK [2][-]{subsection.12.1}{Thresholding}{section.12}% 39
\BOOKMARK [2][-]{subsection.12.2}{True vs. False, Positve vs. Negative}{section.12}% 40
\BOOKMARK [2][-]{subsection.12.3}{Accuracy, Precision and Recall}{section.12}% 41
\BOOKMARK [2][-]{subsection.12.4}{ROC and AUC}{section.12}% 42
\BOOKMARK [2][-]{subsection.12.5}{Prediction Bias}{section.12}% 43
\BOOKMARK [1][-]{section.13}{Regularization: Sparsity}{}% 44
\BOOKMARK [1][-]{section.14}{Neural Networks}{}% 45
\BOOKMARK [2][-]{subsection.14.1}{Hidden Layers}{section.14}% 46
\BOOKMARK [2][-]{subsection.14.2}{Activation Functions}{section.14}% 47
\BOOKMARK [2][-]{subsection.14.3}{Common Activation Functions}{section.14}% 48
\BOOKMARK [1][-]{section.15}{Best Practices when training neural networks}{}% 49
\BOOKMARK [2][-]{subsection.15.1}{Failure Cases}{section.15}% 50
\BOOKMARK [3][-]{subsubsection.15.1.1}{Vanishing Gradients}{subsection.15.1}% 51
\BOOKMARK [3][-]{subsubsection.15.1.2}{Exploding Gradients}{subsection.15.1}% 52
\BOOKMARK [3][-]{subsubsection.15.1.3}{Dead ReLU Units}{subsection.15.1}% 53
\BOOKMARK [2][-]{subsection.15.2}{Dropout Regularization}{section.15}% 54
