\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Framing}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Supervised Machine Learning}{4}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Labels}{4}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Features}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Examples}{4}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Models}{5}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Regression or Classification}{5}{subsection.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Descending into ML}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Linear Regression}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training and Loss}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Shows a high loss model (left) and a low loss model (right)\relax }}{6}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Squared Loss}{6}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Mean Square Error}{6}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Reducing Loss}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Iterative Approach}{7}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Shows the trial and error approach which machine learning algorithms us to train the model\relax }}{7}{figure.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Gradient Decent}{8}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Shows the convex shaped graph\relax }}{8}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Left graph shows the small steps, Middle graph shows the effect of large steps and the Right graph shows the Goldilocks approach\relax }}{8}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Stochastic Gradient Descent - Reducing Loss}{9}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}First Steps with TensorFlow}{9}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces TensorFlow toolkit hierachy\relax }}{10}{figure.caption.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Summary of hyperparameter tuning}{10}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Correlation Matrix}{11}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Generalisation}{11}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax }}{11}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {A complex model for distinguishing sick from healthy trees.}}}{11}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {The model did a bad job predicting new data.}}}{11}{subfigure.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}William of Ockham}{12}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Machine Learning Fine Print}{12}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Training and Test Sets}{13}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Good example of a training and a testing set\relax }}{13}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Validation}{13}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax }}{14}{figure.caption.9}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: importance of validation sets}{{8}{14}{\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Workflow with two partitions of the dataset}}}{14}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Workflow with three partitions of the dataset}}}{14}{subfigure.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Representation}{14}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Feature Engineering}{14}{subsection.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Feature Engineering example\relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{fig: raw to feature}{{9}{15}{Feature Engineering example\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}Mapping Numerical Values}{15}{subsubsection.8.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Mapping numerical values to floating point values\relax }}{15}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.2}Mapping Categorical Values}{15}{subsubsection.8.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces illustrates a one-hot encoding of a particular street: Shorebird Way. The element in the binary vector for Shorebird Way has a value of 1, while the elements for all other streets have values of 0.\relax }}{17}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3}Sparse Representation}{17}{subsubsection.8.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Qualities of Good Features}{17}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1}Avoid rarely used Discrete Feature Values}{17}{subsubsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2}Provide Obvious Meanings}{18}{subsubsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3}Don't mix actual data with "Magic Numbers"}{18}{subsubsection.8.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.4}Account for changes in definitions for Feature Values}{18}{subsubsection.8.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Cleaning Data}{18}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.1}Scaling Feature Values}{18}{subsubsection.8.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.2}Handling Extreme Outliers}{19}{subsubsection.8.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.3}Binning}{19}{subsubsection.8.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Binning Latitude\relax }}{19}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.4}Scrubbing}{20}{subsubsection.8.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Feature Crosses}{20}{section.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Figure showing a model with nonlinearity\relax }}{21}{figure.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Regularisation for Simplicity}{21}{section.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Figure showing the generalization curve\relax }}{21}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Lambda - The Regularization Rate}{22}{subsection.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Lowering the value of lambda tends to yield a flatter histogram\relax }}{22}{figure.caption.16}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Histogram of weights with a high lamda value.}}}{22}{subfigure.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Histogram of weights with a low lamda va'Makefile' has lue.}}}{22}{subfigure.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Learning rate and Lambda}{23}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Logistic Regression}{23}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Loss function for Logistic Regression}{24}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Classification}{24}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Thresholding}{24}{subsection.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}True vs. False, Positve vs. Negative}{24}{subsection.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Accuracy, Precision and Recall}{24}{subsection.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4}ROC and AUC}{25}{subsection.12.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Area Under the ROC Curve\relax }}{25}{figure.caption.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5}Prediction Bias}{25}{subsection.12.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Area Under the ROC Curve\relax }}{26}{figure.caption.18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}Regularization: Sparsity}{26}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}Neural Networks}{26}{section.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces A Complex Nonlinear model\relax }}{27}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces A Linear model as a graph\relax }}{27}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1}Hidden Layers}{27}{subsection.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Graph if a two-layer model\relax }}{28}{figure.caption.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2}Activation Functions}{28}{subsection.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Three-layer model with activation function\relax }}{28}{figure.caption.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3}Common Activation Functions}{28}{subsection.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}Best Practices when training neural networks}{29}{section.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.1}Failure Cases}{29}{subsection.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {15.1.1}Vanishing Gradients}{29}{subsubsection.15.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {15.1.2}Exploding Gradients}{29}{subsubsection.15.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {15.1.3}Dead ReLU Units}{29}{subsubsection.15.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2}Dropout Regularization}{29}{subsection.15.2}\protected@file@percent }
